{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FT67Qv53AvPQ",
        "outputId": "9c30196d-e91b-44c1-8cdb-a4a6ad244877"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, LassoCV, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1QWqfj8vA3vZ"
      },
      "outputs": [],
      "source": [
        "X_train = pd.read_csv('../../data/model_data/X_train.csv').drop(columns=['Unnamed: 0', 'production_countries', 'genres'])\n",
        "X_train['description'] = X_train['description'].fillna('')\n",
        "X_test = pd.read_csv('../../data/model_data/X_test.csv').drop(columns=['Unnamed: 0', 'production_countries', 'genres'])\n",
        "y_train = pd.read_csv('../../data/model_data/y_train.csv').drop(columns=['Unnamed: 0'])\n",
        "y_test = pd.read_csv('../../data/model_data/y_test.csv').drop(columns=['Unnamed: 0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aj2SlzMjAvPW"
      },
      "outputs": [],
      "source": [
        "ohe_columns = ['role', 'type']\n",
        "tfid_columns = ['title', 'description']\n",
        "poly_columns = ['seasons', 'runtime', 'release_year', 'person_id']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAW83kCiAvPX"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JaUvqYZhAvPY"
      },
      "outputs": [],
      "source": [
        "stop_words  = stopwords.words('english')\n",
        "ct_count_vec = ColumnTransformer(\n",
        "                            [\n",
        "                                ('tfid_t', TfidfVectorizer(ngram_range=(1,1), min_df=2), tfid_columns[0]),\n",
        "                                ('tfid_d', TfidfVectorizer(stop_words=stop_words, ngram_range=(1,1), min_df=3), tfid_columns[1]),\n",
        "                            ]\n",
        "                        )\n",
        "ct_count_vec.fit(X_train, y_train)\n",
        "X_train_cv = pd.DataFrame(ct_count_vec.transform(X_train).A, columns=ct_count_vec.get_feature_names_out())\n",
        "X_test_cv = pd.DataFrame(ct_count_vec.transform(X_test).A, columns=ct_count_vec.get_feature_names_out())\n",
        "X_train.drop(columns=tfid_columns, inplace=True)\n",
        "X_test.drop(columns=tfid_columns, inplace=True)\n",
        "\n",
        "X_train = pd.concat([X_train, X_train_cv], axis=1) \n",
        "X_test = pd.concat([X_test, X_test_cv], axis=1) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoTu0EMBAvPY"
      },
      "source": [
        "# GetDummies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2aI_jpdiBFvQ"
      },
      "outputs": [],
      "source": [
        "X_train = pd.concat([X_train, pd.get_dummies(X_train, columns=ohe_columns, drop_first=True)], axis=1).drop(columns=ohe_columns)\n",
        "X_test = pd.concat([X_test, pd.get_dummies(X_test, columns=ohe_columns, drop_first=True)], axis=1).drop(columns=ohe_columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vglj0rReAvPa"
      },
      "source": [
        "# Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZ4L3hfuAvPb",
        "outputId": "87673fa6-c883-4870-e826-718c69c83835"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9869131397326231, 21.889730399252002)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe = Pipeline([\n",
        "    ('ss', StandardScaler()),\n",
        "    ('lasso', LassoCV()),\n",
        "])\n",
        "pipe.fit(X_train, y_train['tmdb_popularity'])\n",
        "preds = pipe.predict(X_test)\n",
        "r2_score(y_test['tmdb_popularity'], preds), mean_squared_error(y_test['tmdb_popularity'], preds, squared=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE: Ran This on google Colab Pro need to rerun to extract best features will incorporate this into my git repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> My model greatly beat the baseline model.  The baselines performance had a percent of variance present in the data that it predicted was -0.0022 while the root_mean_squared_error was 191.56.  Where my percent of variance present in the data that my final model predicted was .987 and had a root_mean_squared_error of 21.89.  In sum the model was good at finding the linear realtionship between HBO Movie/TVShows and IMDB_Score based on a specific set of features my model will help HBO determine if their next show is going to be a hit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "final_model.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "763c58dc754126fdcc508b9f4a084ccf790ec0f71a7031f5e40ea62c092b888e"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('SL_env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
